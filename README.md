## Synopsis

This repo is solutions to the written assignments for Stanford NLP with deep learning class CS224n.

### Assignment 1:

- Deriving word vectors' gradients for 4 different flavours of the word2vec model (skip-gram vs cbow; softmax loss vs negsample loss)
- Deriving the computational complexity of each flavour.

### Assignment 2:

- Deriving the gradients of on RNN language model

### Assignment 3:

- Consider a GRU as an automata and analyzed its toogling and latching behaviors.

## Contributors:

- junior Teudjio Mbativou : https://www.linkedin.com/in/junior-teudjio-3a125b8a


## Acknowledgment

- A big thank you to Stanford university for putting this beautiful learning material open.
- A big thank you to Professors Richard Socher and Chris Manning for teaching the subject in such an intuitive and yet very deep and practical manner.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details